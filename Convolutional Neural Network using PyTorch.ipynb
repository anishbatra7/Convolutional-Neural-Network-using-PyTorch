{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning - CNN Classifier\n",
    "\n",
    "Member 1: Anish Batra, ab8166\n",
    "\n",
    "Member 2: Prashant Mahajan, prm349"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2JHfj0oLWAT"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eaxeDQtmLcWt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms\n",
    "from torch.utils.data import sampler\n",
    "import torch.utils.data\n",
    "import torch.backends.cudnn as cudnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "0j-3uLAxLfTZ",
    "outputId": "7adb4635-4900-42c1-cc05-9698042c7d84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "class getTrainAndValidation(sampler.Sampler):\n",
    "    def __init__(self, num_samples, start=0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    num_train = 49000\n",
    "    num_val = 1000\n",
    "\n",
    "    # Perform data augmentation and normalization\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1991, 0.2010))\n",
    "    ])\n",
    "\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                             (0.2023, 0.1994, 0.2010)),\n",
    "    ])\n",
    "\n",
    "    # Splitting the dataset into 3 parts - Train, Validate and test\n",
    "    trainset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=True, download=True, transform=transform_train)\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        trainset,\n",
    "        batch_size=64,\n",
    "        sampler=getTrainAndValidation(num_train, 0),\n",
    "        num_workers=2)\n",
    "\n",
    "    valset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=True, download=True, transform=transform_train)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        valset,\n",
    "        batch_size=64,\n",
    "        sampler=getTrainAndValidation(num_val, num_train),\n",
    "        num_workers=2)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform_test)\n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=64, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tP4uwH0oLhQW"
   },
   "outputs": [],
   "source": [
    "# Use CUDA\n",
    "device = torch.cuda.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "X-92Nmxi0Okc",
    "outputId": "427b8a59-53ff-44ce-b85a-4c5c07640dc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.cuda.FloatTensor"
      ]
     },
     "execution_count": 32,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iwmz6Fydn09f"
   },
   "outputs": [],
   "source": [
    "print_every = 100\n",
    "\n",
    "# Utility to reset the model if we want to re-intialize all our parameters\n",
    "def reset(m):\n",
    "    if hasattr(m, 'reset_parameters'):\n",
    "        m.reset_parameters()\n",
    "\n",
    "\n",
    "# Flatten is used to convert channels, rows and columns of the data into a single\n",
    "# long vector in Affine layers.\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size()\n",
    "        return x.view(\n",
    "            N, -1)  # Flatten the C* H* W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aBdYKiJRxWa8"
   },
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        #network architecture\n",
    "        self.model = nn.Sequential(\n",
    "            # Conv Layer Block 1: conv-bn-relu-conv-bn-relu-pool\n",
    "            nn.Conv2d(\n",
    "                in_channels=3,\n",
    "                out_channels=32,\n",
    "                kernel_size=3,\n",
    "                stride=1,\n",
    "                padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            # Conv Layer Block 2: conv-bn-relu-conv-bn-relu-pool\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            #     nn.Dropout2d(p=0.05),\n",
    "\n",
    "            # Conv Layer Block 3: conv-bn-relu-conv-bn-relu-pool\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "            Flatten(),\n",
    "            nn.Linear(4 * 4 * 128, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            #     nn.Dropout(p=0.1),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLSmkv7MotCa"
   },
   "outputs": [],
   "source": [
    "def train(model, loss_fn, optimizer, num_epochs=1):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(\"Starting epoch: %d / %d\" % (epoch + 1, num_epochs))\n",
    "        model.train()\n",
    "        for t, (x, y) in enumerate(trainloader):\n",
    "            # Get the inputs\n",
    "            inputs = Variable(x.type(device))\n",
    "            labels = Variable(y.type(device).long())\n",
    "\n",
    "            scores = model(inputs)\n",
    "            loss = loss_fn(scores, labels)\n",
    "\n",
    "            if (t + 1) % print_every == 0:\n",
    "                print('t = %d, loss = %.4f' % (t + 1, loss.item()))\n",
    "\n",
    "            # Optimize the weights\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "def accuracyCheck(model, loader):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking validation set accuracy')\n",
    "    else:\n",
    "        print('Checking Test set accuracy')\n",
    "\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "    ans = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            inputs = Variable(x.type(device))\n",
    "            scores = model(inputs)\n",
    "            _, preds = scores.data.cpu().max(1)\n",
    "\n",
    "            # To export answers\n",
    "            values = preds.cpu().numpy()\n",
    "            ans.extend(values.tolist())\n",
    "\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        accuracy = float(num_correct) / num_samples\n",
    "        print('Accuracy: (%.2f)' % (100 * accuracy))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6851
    },
    "colab_type": "code",
    "id": "YmIeMOAOLjjv",
    "outputId": "6f80798e-dc8b-45cd-b116-20cb515634ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 1 / 50\n",
      "t = 100, loss = 1.4839\n",
      "t = 200, loss = 1.2872\n",
      "t = 300, loss = 1.3412\n",
      "t = 400, loss = 0.8611\n",
      "t = 500, loss = 0.9829\n",
      "t = 600, loss = 0.9628\n",
      "t = 700, loss = 1.0430\n",
      "Starting epoch: 2 / 50\n",
      "t = 100, loss = 0.7547\n",
      "t = 200, loss = 0.9673\n",
      "t = 300, loss = 0.9506\n",
      "t = 400, loss = 0.7634\n",
      "t = 500, loss = 0.6585\n",
      "t = 600, loss = 0.8277\n",
      "t = 700, loss = 0.9160\n",
      "Starting epoch: 3 / 50\n",
      "t = 100, loss = 0.5334\n",
      "t = 200, loss = 0.8791\n",
      "t = 300, loss = 0.6889\n",
      "t = 400, loss = 0.6099\n",
      "t = 500, loss = 0.7906\n",
      "t = 600, loss = 0.7397\n",
      "t = 700, loss = 0.7349\n",
      "Starting epoch: 4 / 50\n",
      "t = 100, loss = 0.5976\n",
      "t = 200, loss = 0.7948\n",
      "t = 300, loss = 0.6707\n",
      "t = 400, loss = 0.5771\n",
      "t = 500, loss = 0.5224\n",
      "t = 600, loss = 0.6420\n",
      "t = 700, loss = 0.7429\n",
      "Starting epoch: 5 / 50\n",
      "t = 100, loss = 0.3827\n",
      "t = 200, loss = 0.6106\n",
      "t = 300, loss = 0.6311\n",
      "t = 400, loss = 0.4884\n",
      "t = 500, loss = 0.5797\n",
      "t = 600, loss = 0.5618\n",
      "t = 700, loss = 0.7788\n",
      "Starting epoch: 6 / 50\n",
      "t = 100, loss = 0.4329\n",
      "t = 200, loss = 0.5717\n",
      "t = 300, loss = 0.5193\n",
      "t = 400, loss = 0.5771\n",
      "t = 500, loss = 0.6809\n",
      "t = 600, loss = 0.4891\n",
      "t = 700, loss = 0.7939\n",
      "Starting epoch: 7 / 50\n",
      "t = 100, loss = 0.4167\n",
      "t = 200, loss = 0.6184\n",
      "t = 300, loss = 0.5469\n",
      "t = 400, loss = 0.5958\n",
      "t = 500, loss = 0.6134\n",
      "t = 600, loss = 0.4893\n",
      "t = 700, loss = 0.6901\n",
      "Starting epoch: 8 / 50\n",
      "t = 100, loss = 0.3780\n",
      "t = 200, loss = 0.5088\n",
      "t = 300, loss = 0.5630\n",
      "t = 400, loss = 0.4626\n",
      "t = 500, loss = 0.6190\n",
      "t = 600, loss = 0.4237\n",
      "t = 700, loss = 0.7557\n",
      "Starting epoch: 9 / 50\n",
      "t = 100, loss = 0.3864\n",
      "t = 200, loss = 0.3999\n",
      "t = 300, loss = 0.3948\n",
      "t = 400, loss = 0.4764\n",
      "t = 500, loss = 0.5688\n",
      "t = 600, loss = 0.4202\n",
      "t = 700, loss = 0.5902\n",
      "Starting epoch: 10 / 50\n",
      "t = 100, loss = 0.3844\n",
      "t = 200, loss = 0.4541\n",
      "t = 300, loss = 0.4211\n",
      "t = 400, loss = 0.3858\n",
      "t = 500, loss = 0.5862\n",
      "t = 600, loss = 0.4592\n",
      "t = 700, loss = 0.5357\n",
      "Starting epoch: 11 / 50\n",
      "t = 100, loss = 0.2800\n",
      "t = 200, loss = 0.6211\n",
      "t = 300, loss = 0.4431\n",
      "t = 400, loss = 0.4670\n",
      "t = 500, loss = 0.5199\n",
      "t = 600, loss = 0.3543\n",
      "t = 700, loss = 0.6957\n",
      "Starting epoch: 12 / 50\n",
      "t = 100, loss = 0.2921\n",
      "t = 200, loss = 0.4216\n",
      "t = 300, loss = 0.4237\n",
      "t = 400, loss = 0.3366\n",
      "t = 500, loss = 0.4992\n",
      "t = 600, loss = 0.4598\n",
      "t = 700, loss = 0.5759\n",
      "Starting epoch: 13 / 50\n",
      "t = 100, loss = 0.2978\n",
      "t = 200, loss = 0.4415\n",
      "t = 300, loss = 0.4887\n",
      "t = 400, loss = 0.4054\n",
      "t = 500, loss = 0.5437\n",
      "t = 600, loss = 0.4494\n",
      "t = 700, loss = 0.4885\n",
      "Starting epoch: 14 / 50\n",
      "t = 100, loss = 0.2692\n",
      "t = 200, loss = 0.4755\n",
      "t = 300, loss = 0.3688\n",
      "t = 400, loss = 0.3416\n",
      "t = 500, loss = 0.3740\n",
      "t = 600, loss = 0.3556\n",
      "t = 700, loss = 0.5951\n",
      "Starting epoch: 15 / 50\n",
      "t = 100, loss = 0.3245\n",
      "t = 200, loss = 0.3805\n",
      "t = 300, loss = 0.3541\n",
      "t = 400, loss = 0.3667\n",
      "t = 500, loss = 0.6008\n",
      "t = 600, loss = 0.4546\n",
      "t = 700, loss = 0.4255\n",
      "Starting epoch: 16 / 50\n",
      "t = 100, loss = 0.3062\n",
      "t = 200, loss = 0.5450\n",
      "t = 300, loss = 0.3837\n",
      "t = 400, loss = 0.3437\n",
      "t = 500, loss = 0.3922\n",
      "t = 600, loss = 0.2629\n",
      "t = 700, loss = 0.5192\n",
      "Starting epoch: 17 / 50\n",
      "t = 100, loss = 0.3138\n",
      "t = 200, loss = 0.2505\n",
      "t = 300, loss = 0.2682\n",
      "t = 400, loss = 0.3245\n",
      "t = 500, loss = 0.5468\n",
      "t = 600, loss = 0.3862\n",
      "t = 700, loss = 0.5415\n",
      "Starting epoch: 18 / 50\n",
      "t = 100, loss = 0.2698\n",
      "t = 200, loss = 0.2969\n",
      "t = 300, loss = 0.4476\n",
      "t = 400, loss = 0.3487\n",
      "t = 500, loss = 0.3579\n",
      "t = 600, loss = 0.3222\n",
      "t = 700, loss = 0.3978\n",
      "Starting epoch: 19 / 50\n",
      "t = 100, loss = 0.2417\n",
      "t = 200, loss = 0.3570\n",
      "t = 300, loss = 0.2697\n",
      "t = 400, loss = 0.4214\n",
      "t = 500, loss = 0.3199\n",
      "t = 600, loss = 0.3594\n",
      "t = 700, loss = 0.4436\n",
      "Starting epoch: 20 / 50\n",
      "t = 100, loss = 0.2015\n",
      "t = 200, loss = 0.3218\n",
      "t = 300, loss = 0.3646\n",
      "t = 400, loss = 0.3000\n",
      "t = 500, loss = 0.3932\n",
      "t = 600, loss = 0.2651\n",
      "t = 700, loss = 0.5414\n",
      "Starting epoch: 21 / 50\n",
      "t = 100, loss = 0.2319\n",
      "t = 200, loss = 0.3491\n",
      "t = 300, loss = 0.4287\n",
      "t = 400, loss = 0.3531\n",
      "t = 500, loss = 0.4356\n",
      "t = 600, loss = 0.3185\n",
      "t = 700, loss = 0.3961\n",
      "Starting epoch: 22 / 50\n",
      "t = 100, loss = 0.2090\n",
      "t = 200, loss = 0.3590\n",
      "t = 300, loss = 0.3999\n",
      "t = 400, loss = 0.3387\n",
      "t = 500, loss = 0.4058\n",
      "t = 600, loss = 0.3243\n",
      "t = 700, loss = 0.5142\n",
      "Starting epoch: 23 / 50\n",
      "t = 100, loss = 0.1668\n",
      "t = 200, loss = 0.3549\n",
      "t = 300, loss = 0.2233\n",
      "t = 400, loss = 0.2865\n",
      "t = 500, loss = 0.3557\n",
      "t = 600, loss = 0.2870\n",
      "t = 700, loss = 0.4354\n",
      "Starting epoch: 24 / 50\n",
      "t = 100, loss = 0.1770\n",
      "t = 200, loss = 0.2454\n",
      "t = 300, loss = 0.3249\n",
      "t = 400, loss = 0.3587\n",
      "t = 500, loss = 0.4956\n",
      "t = 600, loss = 0.3835\n",
      "t = 700, loss = 0.4199\n",
      "Starting epoch: 25 / 50\n",
      "t = 100, loss = 0.2407\n",
      "t = 200, loss = 0.4117\n",
      "t = 300, loss = 0.3117\n",
      "t = 400, loss = 0.3049\n",
      "t = 500, loss = 0.4678\n",
      "t = 600, loss = 0.3334\n",
      "t = 700, loss = 0.4385\n",
      "Starting epoch: 26 / 50\n",
      "t = 100, loss = 0.1534\n",
      "t = 200, loss = 0.4801\n",
      "t = 300, loss = 0.3734\n",
      "t = 400, loss = 0.4065\n",
      "t = 500, loss = 0.4554\n",
      "t = 600, loss = 0.1883\n",
      "t = 700, loss = 0.4503\n",
      "Starting epoch: 27 / 50\n",
      "t = 100, loss = 0.1614\n",
      "t = 200, loss = 0.3302\n",
      "t = 300, loss = 0.4356\n",
      "t = 400, loss = 0.2885\n",
      "t = 500, loss = 0.3764\n",
      "t = 600, loss = 0.2911\n",
      "t = 700, loss = 0.5155\n",
      "Starting epoch: 28 / 50\n",
      "t = 100, loss = 0.2631\n",
      "t = 200, loss = 0.3140\n",
      "t = 300, loss = 0.3678\n",
      "t = 400, loss = 0.3138\n",
      "t = 500, loss = 0.5063\n",
      "t = 600, loss = 0.3204\n",
      "t = 700, loss = 0.5149\n",
      "Starting epoch: 29 / 50\n",
      "t = 100, loss = 0.1925\n",
      "t = 200, loss = 0.2013\n",
      "t = 300, loss = 0.2668\n",
      "t = 400, loss = 0.1945\n",
      "t = 500, loss = 0.3485\n",
      "t = 600, loss = 0.1988\n",
      "t = 700, loss = 0.4132\n",
      "Starting epoch: 30 / 50\n",
      "t = 100, loss = 0.2298\n",
      "t = 200, loss = 0.4486\n",
      "t = 300, loss = 0.2289\n",
      "t = 400, loss = 0.2732\n",
      "t = 500, loss = 0.4578\n",
      "t = 600, loss = 0.2437\n",
      "t = 700, loss = 0.3958\n",
      "Starting epoch: 31 / 50\n",
      "t = 100, loss = 0.2248\n",
      "t = 200, loss = 0.3221\n",
      "t = 300, loss = 0.3563\n",
      "t = 400, loss = 0.3824\n",
      "t = 500, loss = 0.3017\n",
      "t = 600, loss = 0.2314\n",
      "t = 700, loss = 0.3742\n",
      "Starting epoch: 32 / 50\n",
      "t = 100, loss = 0.2293\n",
      "t = 200, loss = 0.3039\n",
      "t = 300, loss = 0.3769\n",
      "t = 400, loss = 0.3607\n",
      "t = 500, loss = 0.2897\n",
      "t = 600, loss = 0.1855\n",
      "t = 700, loss = 0.3148\n",
      "Starting epoch: 33 / 50\n",
      "t = 100, loss = 0.1300\n",
      "t = 200, loss = 0.2352\n",
      "t = 300, loss = 0.3220\n",
      "t = 400, loss = 0.3566\n",
      "t = 500, loss = 0.3363\n",
      "t = 600, loss = 0.3206\n",
      "t = 700, loss = 0.4274\n",
      "Starting epoch: 34 / 50\n",
      "t = 100, loss = 0.3225\n",
      "t = 200, loss = 0.3776\n",
      "t = 300, loss = 0.3379\n",
      "t = 400, loss = 0.3656\n",
      "t = 500, loss = 0.3205\n",
      "t = 600, loss = 0.2970\n",
      "t = 700, loss = 0.4550\n",
      "Starting epoch: 35 / 50\n",
      "t = 100, loss = 0.2018\n",
      "t = 200, loss = 0.3933\n",
      "t = 300, loss = 0.3187\n",
      "t = 400, loss = 0.3394\n",
      "t = 500, loss = 0.4076\n",
      "t = 600, loss = 0.2310\n",
      "t = 700, loss = 0.4517\n",
      "Starting epoch: 36 / 50\n",
      "t = 100, loss = 0.1433\n",
      "t = 200, loss = 0.3252\n",
      "t = 300, loss = 0.2576\n",
      "t = 400, loss = 0.2510\n",
      "t = 500, loss = 0.3098\n",
      "t = 600, loss = 0.1682\n",
      "t = 700, loss = 0.3937\n",
      "Starting epoch: 37 / 50\n",
      "t = 100, loss = 0.2902\n",
      "t = 200, loss = 0.1701\n",
      "t = 300, loss = 0.2285\n",
      "t = 400, loss = 0.3641\n",
      "t = 500, loss = 0.2788\n",
      "t = 600, loss = 0.2334\n",
      "t = 700, loss = 0.4719\n",
      "Starting epoch: 38 / 50\n",
      "t = 100, loss = 0.2321\n",
      "t = 200, loss = 0.2349\n",
      "t = 300, loss = 0.2218\n",
      "t = 400, loss = 0.3493\n",
      "t = 500, loss = 0.3832\n",
      "t = 600, loss = 0.3212\n",
      "t = 700, loss = 0.3909\n",
      "Starting epoch: 39 / 50\n",
      "t = 100, loss = 0.2594\n",
      "t = 200, loss = 0.3593\n",
      "t = 300, loss = 0.2528\n",
      "t = 400, loss = 0.2549\n",
      "t = 500, loss = 0.4470\n",
      "t = 600, loss = 0.1844\n",
      "t = 700, loss = 0.5115\n",
      "Starting epoch: 40 / 50\n",
      "t = 100, loss = 0.1550\n",
      "t = 200, loss = 0.3503\n",
      "t = 300, loss = 0.4169\n",
      "t = 400, loss = 0.2934\n",
      "t = 500, loss = 0.3309\n",
      "t = 600, loss = 0.2442\n",
      "t = 700, loss = 0.3319\n",
      "Starting epoch: 41 / 50\n",
      "t = 100, loss = 0.1918\n",
      "t = 200, loss = 0.2562\n",
      "t = 300, loss = 0.2256\n",
      "t = 400, loss = 0.4086\n",
      "t = 500, loss = 0.4226\n",
      "t = 600, loss = 0.2552\n",
      "t = 700, loss = 0.3927\n",
      "Starting epoch: 42 / 50\n",
      "t = 100, loss = 0.1585\n",
      "t = 200, loss = 0.2493\n",
      "t = 300, loss = 0.2689\n",
      "t = 400, loss = 0.3987\n",
      "t = 500, loss = 0.3751\n",
      "t = 600, loss = 0.2103\n",
      "t = 700, loss = 0.4018\n",
      "Starting epoch: 43 / 50\n",
      "t = 100, loss = 0.2303\n",
      "t = 200, loss = 0.3345\n",
      "t = 300, loss = 0.2974\n",
      "t = 400, loss = 0.4759\n",
      "t = 500, loss = 0.3231\n",
      "t = 600, loss = 0.2715\n",
      "t = 700, loss = 0.3575\n",
      "Starting epoch: 44 / 50\n",
      "t = 100, loss = 0.1838\n",
      "t = 200, loss = 0.2973\n",
      "t = 300, loss = 0.3197\n",
      "t = 400, loss = 0.1776\n",
      "t = 500, loss = 0.4178\n",
      "t = 600, loss = 0.2669\n",
      "t = 700, loss = 0.4405\n",
      "Starting epoch: 45 / 50\n",
      "t = 100, loss = 0.2617\n",
      "t = 200, loss = 0.2226\n",
      "t = 300, loss = 0.2316\n",
      "t = 400, loss = 0.2049\n",
      "t = 500, loss = 0.2995\n",
      "t = 600, loss = 0.3333\n",
      "t = 700, loss = 0.3434\n",
      "Starting epoch: 46 / 50\n",
      "t = 100, loss = 0.1640\n",
      "t = 200, loss = 0.2325\n",
      "t = 300, loss = 0.2088\n",
      "t = 400, loss = 0.3968\n",
      "t = 500, loss = 0.3093\n",
      "t = 600, loss = 0.2124\n",
      "t = 700, loss = 0.4173\n",
      "Starting epoch: 47 / 50\n",
      "t = 100, loss = 0.2651\n",
      "t = 200, loss = 0.2587\n",
      "t = 300, loss = 0.3850\n",
      "t = 400, loss = 0.2877\n",
      "t = 500, loss = 0.3825\n",
      "t = 600, loss = 0.2655\n",
      "t = 700, loss = 0.3853\n",
      "Starting epoch: 48 / 50\n",
      "t = 100, loss = 0.2429\n",
      "t = 200, loss = 0.3109\n",
      "t = 300, loss = 0.3478\n",
      "t = 400, loss = 0.2832\n",
      "t = 500, loss = 0.3186\n",
      "t = 600, loss = 0.2300\n",
      "t = 700, loss = 0.3162\n",
      "Starting epoch: 49 / 50\n",
      "t = 100, loss = 0.2282\n",
      "t = 200, loss = 0.3452\n",
      "t = 300, loss = 0.2412\n",
      "t = 400, loss = 0.2743\n",
      "t = 500, loss = 0.2583\n",
      "t = 600, loss = 0.1689\n",
      "t = 700, loss = 0.4729\n",
      "Starting epoch: 50 / 50\n",
      "t = 100, loss = 0.2216\n",
      "t = 200, loss = 0.3642\n",
      "t = 300, loss = 0.2742\n",
      "t = 400, loss = 0.2857\n",
      "t = 500, loss = 0.2728\n",
      "t = 600, loss = 0.3141\n",
      "t = 700, loss = 0.2728\n",
      "Checking validation set accuracy\n",
      "Accuracy: (85.70)\n"
     ]
    }
   ],
   "source": [
    "# convnet = ShuffleNetV2()\n",
    "convnet = CNN()\n",
    "convnet.cuda()\n",
    "\n",
    "# loss function\n",
    "loss_fn = nn.CrossEntropyLoss().type(device)\n",
    "optimizer = optim.Adam(\n",
    "    list(convnet.parameters()), lr=0.001, weight_decay=5e-4, betas=(0.9, 0.99))\n",
    "\n",
    "train(convnet, loss_fn, optimizer, num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "6mvISLapxwF6",
    "outputId": "6e5cceff-c1fb-47f3-ac74-a7c01ba96249"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking validation set accuracy\n",
      "Accuracy: (86.90)\n"
     ]
    }
   ],
   "source": [
    "ans = accuracyCheck(convnet, valloader)\n",
    "np.save('ans2-uni.npy', np.array(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "d_zBO6lRo0xt"
   },
   "source": [
    "\n",
    "# Model Description - \n",
    "\n",
    "**Architecture Selection:**\n",
    "\n",
    "- First implemented a simple convolutional model with one convolutional layer. \n",
    "\n",
    "- Initial architecture : [conv-relu-pool] x 2 - [affine] - [softmax]\n",
    "\n",
    "- After the initial architecture various different architectures were tested, concluding the following final architure -  [conv-batchnorm-relu-pool] x 3 - [affine] - [softmax]\n",
    "\n",
    "- Implementing Batch normalization resulted in improvement of training speed. \n",
    "- Tried adding dropout to the model. Since model didn't overfit, the accuracy was unaffected. \n",
    "\n",
    "**Activation Functions**\n",
    "\n",
    "- Altrhought `Relu` is considered most popular in training CNNs, I used `Adam` optimizer here as it is considered fairly robust to the choice of hyper parameters. (Credits: [Standford Lecture Series](https://youtu.be/LxfUGhug-iQ))\n",
    "- Adding parameters - `weight_decay` and  `betas` resulted in 5% improvement in the performance \n",
    "- Experimentation with learning rate didn't produce any substantial results.\n",
    "\n",
    "For loss function standard `CrossEntropy` function is used.\n",
    "\n",
    "**Experimentation**\n",
    "- Kernels: Tried kernels of size 5 x 5 and 7 x 7, still 3 x 3 kernel gives out the best results\n",
    "- Data Augmentation: Augmentated the training dataset horizontally to get variation in the dataset \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW1-CNN-uni.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
